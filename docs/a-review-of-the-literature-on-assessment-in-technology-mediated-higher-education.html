<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Approaches to Assessment in Higher Education</title>
  <meta name="description" content="This site hosts the open development of my PhD dissertation at University of Victoria." />
  <meta name="generator" content="bookdown 0.25.5 and GitBook 2.6.7" />

  <meta property="og:title" content="Approaches to Assessment in Higher Education" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This site hosts the open development of my PhD dissertation at University of Victoria." />
  <meta name="github-repo" content="cmadland/assessment" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Approaches to Assessment in Higher Education" />
  
  <meta name="twitter:description" content="This site hosts the open development of my PhD dissertation at University of Victoria." />
  

<meta name="author" content="Colin Madland" />


<meta name="date" content="2022-07-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="https://hypothes.is/embed.js" async></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Assessment in Higher Education</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><i class="fa fa-check"></i>A Review of the Literature on Assessment in Technology-mediated Higher Education</a>
<ul>
<li class="chapter" data-level="" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#introduction"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#a-brief-history-of-classroom-assessment-research"><i class="fa fa-check"></i>A Brief History of Classroom Assessment Research</a>
<ul>
<li class="chapter" data-level="0.0.1" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#professional-standards-assessment-literacy"><i class="fa fa-check"></i><b>0.0.1</b> Professional Standards / Assessment Literacy</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#factors"><i class="fa fa-check"></i>Factors</a>
<ul>
<li class="chapter" data-level="" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#assessment-cultures"><i class="fa fa-check"></i>Assessment Cultures</a></li>
<li class="chapter" data-level="0.0.2" data-path="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html"><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#impact-of-technology-on-approaches-to-assessment-in-higher-education"><i class="fa fa-check"></i><b>0.0.2</b> Impact Of Technology On Approaches To Assessment In Higher Education</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/cmadland/assessment" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Approaches to Assessment in Higher Education</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Approaches to Assessment in Higher Education</h1>
<p class="author"><em>Colin Madland</em></p>
<p class="date"><em>2022-07-03</em></p>
</div>
<div id="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education" class="section level1 unnumbered hasAnchor">
<h1>A Review of the Literature on Assessment in Technology-mediated Higher Education<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li><a href="#a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education--">A Review of the Literature on Assessment in Technology-mediated Higher Education {-}</a>
<ul>
<li><a href="#introduction--">Introduction {-}</a></li>
<li><a href="#a-brief-history-of-classroom-assessment-research--">A Brief History of Classroom Assessment Research {-}</a>
<ul>
<li><a href="#professional-standards--assessment-literacy">Professional Standards / Assessment Literacy</a></li>
<li><a href="#approaches-to-assessment">Approaches to Assessment</a></li>
</ul></li>
<li><a href="#factors--">Factors {-}</a>
<ul>
<li><a href="#assessment-cultures--">Assessment Cultures {-}</a></li>
<li><a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#impact-of-technology-on-approaches-to-assessment-in-higher-education">Impact Of Technology On Approaches To Assessment In Higher Education</a></li>
</ul></li>
</ul></li>
</ul>
<div id="introduction" class="section level2 unnumbered hasAnchor">
<h2>Introduction<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Assessing learning is a critical component of the work of higher education instructors, yet not enough is known about how instructors plan for and make decisions about how they will assess their students’ learning, particularly in the context of technology-mediated environments. In her important article, Shepard <span class="citation">(<a href="#ref-shepardRoleAssessmentLearning2000" role="doc-biblioref">2000</a>)</span> argued at the turn of the century that contemporary (at the time) assessment structures originated in past models of curriculum and instruction which were popular in the early 1900s. These curricular models emphasized the work of psychologists like Thorndike <span class="citation">(<a href="#ref-thorndikeElementsPsychology1905" role="doc-biblioref">Thorndike, 1905</a>)</span> and Skinner <span class="citation">(<a href="#ref-skinnerBehaviourOrganisms1938" role="doc-biblioref">Skinner, 1938</a>)</span> who viewed the process of learning as being grounded in the mechanistic view of behaviourism where learning is the result of the precise and controlled input of ‘knowledge’ and reinforced with rewards for correct responses. As such, instructors (appropriately at the time) designed their assessments to align with the curricular goals of the time and assessed learning by determining whether or not a learner could provide the single correct response to a given question at a time removed from the instruction. However, in the latter half of the 20th century, when western psychologists discovered the ideas of Lev Vygotsky <span class="citation">(<a href="#ref-vygotskyMindSociety1978" role="doc-biblioref">Vygotsky, 1978</a>)</span>, a contemporary of the previously mentioned psychologists, curricula began to take a more social-constructivist approach that emphasized higher-order thinking, problem-solving in social contexts, and metacognitive skills over rote memorization. Unfortunately, it seemed that the efficiencies of testing memory, recognition, and recall through selected-response tests were too deeply embedded in the practices of HE instructors who resisted changing their assessments to match the new curricular goals. Barnett <span class="citation">(<a href="#ref-barnettWillLearnBeing2007" role="doc-biblioref">2007</a>)</span> contends that these new goals lead to a state of <em>supercomplexity</em> with which both learners and instructors must grapple, and which Garrison et al. <span class="citation">(<a href="#ref-garrisonThinkingCollaborativelyEducational2015" role="doc-biblioref">2015</a>)</span> argue requires deep changes to how instructors approach teaching and how learners approach learning.</p>
<p>Shepard argues for the need to integrate assessment and instruction in such a way as to engage learners in authentic performance tasks more suited to modern understandings of cognition. It appears now that, in the twenty-two years since Shepard wrote her paper, the goals of early 21st century curricula have continued to diverge from those of the 20th century with the World Economic Forum identifying competencies in collaboration, analytical thinking, creative problem-solving, and continual learning as being priorities for 21st century employers <span class="citation">(<a href="#ref-worldeconomicforumFutureJobsReport2020" role="doc-biblioref">Forum, 2020</a>)</span>. Additionally, digital and networked technologies have become ubiquitous in society and higher education <span class="citation">(<a href="#ref-broadfootAssessmentTwentyFirstCenturyLearning2016" role="doc-biblioref">Broadfoot, 2016</a>; <a href="#ref-pellegrinoPerspectivesIntegrationTechnology2010" role="doc-biblioref">Pellegrino &amp; Quellmalz, 2010</a>; <a href="#ref-webbAssessmentTwentyFirstCentury2018" role="doc-biblioref">Webb &amp; Ifenthaler, 2018</a>)</span> and the influence of digital technologies on instructors approaches to assessment remains under researched. Models of assessment which prioritize testing skills in a manner aligned with 20th century curricular models are no longer adequate because they no longer align with the priorities of modern HE <span class="citation">(<a href="#ref-broadfootAssessmentTwentyFirstCenturyLearning2016" role="doc-biblioref">Broadfoot, 2016</a>; <a href="#ref-crooksImpactClassroomEvaluation1988" role="doc-biblioref">Crooks, 1988</a>; <a href="#ref-pellegrinoPerspectivesIntegrationTechnology2010" role="doc-biblioref">Pellegrino &amp; Quellmalz, 2010</a>; <a href="#ref-timmisRethinkingAssessmentDigital2016" role="doc-biblioref">Timmis et al., 2016</a>)</span>.</p>
<p>Despite Shepard’s exhortation to integrate modern curricular goals with aligned assessment practices, both local and systemic change in this area has been elusive <span class="citation">(<a href="#ref-broadfootAssessmentTwentyFirstCenturyLearning2016" role="doc-biblioref">Broadfoot, 2016</a>; <a href="#ref-earlAssessmentLearningUsing2013" role="doc-biblioref">Earl, 2013</a>)</span>. This is in part because the approaches that individual instructors take to assessment are driven by complex factors at the individual level as well as local and systemic levels <span class="citation">(<a href="#ref-blackAssessmentClassroomLearning1998" role="doc-biblioref">Black &amp; Wiliam, 1998</a>; <a href="#ref-delucaDifferentialSituatedView2019" role="doc-biblioref">DeLuca, Coombs, et al., 2019</a>; <a href="#ref-willisConceptualisingTeachersAssessment2013" role="doc-biblioref">Willis et al., 2013</a>)</span>. The variety of factors, combined with the relative freedom instructors have to design their courses and assessments leads to approaches to assessment that are variable, idiosyncratic, and often influenced by individual instructors’ past experiences rather than a deep understanding of assessment theory <span class="citation">(<a href="#ref-lipnevichWhatGradesMean2020" role="doc-biblioref">Lipnevich et al., 2020</a>; <a href="#ref-masseyAssessmentLiteracyCollege2020" role="doc-biblioref">Massey et al., 2020</a>)</span>.</p>
<!--
[@wellerGoodOnlineLearning2022]
-->
<p>{–Researchers are engaged in important work exploring how K12 teachers approach assessment in their classrooms, including DeLuca et al.’s <span class="citation">(<a href="#ref-delucaApproachesClassroomAssessment2016" role="doc-biblioref">2016</a>)</span> <em>Approaches to Classroom Assessment Inventory</em>, but there has been less work in relation to technology-mediated higher education. –}</p>
<p>Given the confluence of the preceding factors, the purpose of this literature review will be to synthesize and analyze the literature related to approaches to assessment among higher education instructors. The review will begin with a survey of historical conceptions of assessment, followed by a deeper analysis of the literature since 2010 with a focus on assessment in technologically-mediated higher education.</p>
<p>This review is guided by four research questions:</p>
<ol style="list-style-type: decimal">
<li>What factors shape higher education instructors’ approaches to assessment?</li>
<li>What are the major themes or patterns in the literature related to approaches to assessment in higher education?<br />
</li>
<li>What are the major themes or patterns in the literature related to the impact of technology on assessment in higher education?<br />
</li>
<li>What gaps exist in the literature related to approaches to assessment in technology-mediated higher education?</li>
</ol>
</div>
<div id="a-brief-history-of-classroom-assessment-research" class="section level2 unnumbered hasAnchor">
<h2>A Brief History of Classroom Assessment Research<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#a-brief-history-of-classroom-assessment-research" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are deep and rich bodies of literature addressing educational assessment <em>writ large</em>, and it would not be possible in the scope of this article to adequately cover the full breadth and depth of the published research <span class="citation">(<a href="#ref-joughinAssessmentLearningJudgement2009a" role="doc-biblioref">Joughin, 2009</a>)</span>. Consequently, while any starting point may seem somewhat arbitrary, the author chose to begin with the genesis of modern thinking of assessment being divided into “summative assessment” (for the purposes of providing a final judgement of learning) and “formative assessment” (for the purposes of providing feedback to learners and instructors to improve learning). This framing of assessment was popularized by Benjamin Bloom and remains prominent in the literature.</p>
<p>Among the more influential publications related to modern views of assessment (then usually called “evaluation”) was Scriven’s <span class="citation">(<a href="#ref-scrivenMethodologyEvaluation1967" role="doc-biblioref">1967</a>)</span> article in which he drew distinctions between “formative” and “summative” evaluation. Formative evaluation was described as evaluation for the purposes of improvement, and summative evaluation was seen as a validation of the quality of work at the end of a process. This distinction was quickly incorporated into Bloom’s <span class="citation">(<a href="#ref-bloomLearningMasteryInstruction1968" role="doc-biblioref">1968</a>)</span> ideas related to mastery learning and began to be promoted as a model for educational reform. However, by the late 1990s, when Black and Wiliam <span class="citation">(<a href="#ref-blackAssessmentClassroomLearning1998" role="doc-biblioref">1998</a>)</span> published their landmark review of the literature on assessment, the idea of formative assessment was still not well-defined or implemented. Black and Wiliam framed formative assessment as “encompassing all those activities undertaken by teachers, and/or by their students, which provide information to be used as feedback to modify the teaching and learning activities in which they are engaged” <span class="citation">(<a href="#ref-blackAssessmentClassroomLearning1998" role="doc-biblioref">1998, pp. 7–8</a>)</span>. Although Black and Wiliam came to very strongly-stated conclusions about the value of formative assessments (e.g. “The research reported here shows conclusively that formative assessment does improve learning. The gains in achievement appear to be quite considerable, and as noted earlier, amongst the largest ever reported for educational interventions.” <span class="citation">(<a href="#ref-blackAssessmentClassroomLearning1998" role="doc-biblioref">1998, p. 61</a>)</span>), reliance on summative assessments in HE has remained high <span class="citation">(<a href="#ref-harlenSystematicReviewImpact2002" role="doc-biblioref">Harlen &amp; Deakin Crick, 2002</a>; <a href="#ref-hebertOnlineRemoteProctoring2021" role="doc-biblioref">Hébert, 2021</a>; <a href="#ref-lipnevichWhatGradesMean2020" role="doc-biblioref">Lipnevich et al., 2020</a>)</span>.</p>
<p>Towards the end of the 20th century, the idea of <em>assessment literacy</em> was introduced by Richard Stiggins<span class="citation">(<a href="#ref-stigginsAssessmentLiteracy1991" role="doc-biblioref">1991</a>)</span>. Stiggins argued that, in K12 educational contexts, society had come to expect high educational attainment, but teacher education programs did little or nothing to prepare graduates to be able to certify that their learners were actually meeting targets. Stiggins blamed this in part on the fact that in the United States, there was no specific requirement for teachers to be trained in assessment, and consequently, teachers, administrators, and those who train them were essentially assessment illiterate. Stiggins described assessment literate educators as those who “have a basic understanding of the meaning of high- and low quality assessment and are able to apply that knowledge to various measures of student achievement” (p. 535).</p>
<p>The National Research Council’s (NRC) 2001 foundational report <em>Knowing What Students Know: The Science and Design of Educational Assessment</em>, advanced understanding of assessment with their definition of assessment as “a process of drawing reasonable inferences about what students know on the basis of evidence derived from observations of what they say, do, or make in selected situations” <span class="citation">(<a href="#ref-pellegrinoKnowingWhatStudents2001" role="doc-biblioref">Pellegrino et al., 2001, p. 112</a>)</span> or, more simply, “reasoning from evidence” <span class="citation">(<a href="#ref-pellegrinoKnowingWhatStudents2001" role="doc-biblioref">Pellegrino et al., 2001, p. 43</a>)</span>, based on Mislevy’s <span class="citation">(<a href="#ref-mislevyTestTheoryReconcieved1994" role="doc-biblioref">1994, p. 4</a>)</span> assertion that “test theory is machinery for reasoning from students’ behavior to conjectures about their competence, as framed in a particular conception of competence.”. Such a parsimonious description, however, may hide some of the complexities of fairly and equitably coming to know what learners know and can do in relation to particular outcomes. Since knowledge of a particular domain cannot be directly observed in a learner, and therefore cannot be quantified, instructors must rely on data gathered during the teaching process to support a particular inference about what a learner <em>probably</em> knows. The data gathered from performance tasks such as exams, essays, portfolios, labs, etc, become <em>evidence</em> when they support an inference about what a learner knows and can do.</p>
<p>More recently, researchers have increasingly recognized the complexity of assessment practices and the factors which drive them. Brown <span class="citation">(<a href="#ref-brownTeachersConceptionsAssessment2004" role="doc-biblioref">2004</a>)</span> showed in a study of K12 teachers in New Zealand that teachers’ “conceptions of assessment” (p. 302), or the organizing frameworks teachers use to understand the phenomenon of assessment, are not simple constructs, but are complex and interconnected. Brown’s model shows four common conceptions of assessment among K12 teachers:</p>
<ul>
<li>improvement of teaching and learning,<br />
</li>
<li>school accountability,<br />
</li>
<li>student accountability, or<br />
</li>
<li>treating assessment as irrelevant.</li>
</ul>
<p>James <span class="citation">(<a href="#ref-jamesAssessmentLearning2008" role="doc-biblioref">2008</a>)</span> highlights important connections between assessment practices and learning theory, noting that both behaviourism and cognitivism emphasize the acquisition of knowledge as a sort of commodity and thus both lead to assessment strategies that emphasize the individual reproduction of knowlege that has either been taught, or has been constructed in meaning-making exercises. Contrary to these approaches, socio-cultural learning theory emphasizes the communal production of meaning through social tools and social interactions between peers and more capable ‘others’. Thus, assessment in socio-cultural contexts, which James argues is under-theorized, ought to be holistic and situated within the communal learning process, rather than an event that happens sometime after the learning has happened. Similarly, Fletcher et al. <span class="citation">(<a href="#ref-fletcherFacultyStudentsConceptions2012" role="doc-biblioref">2012</a>)</span> note that teachers who view teaching as the transmission of knowledge tend to rely more heavily on assessment tasks which require learners to reproduce what they have been taught. On the other hand, teachers who take a more socio-constructivist view that knowledge is built over time tend to conceive of assessment as being an integral part of the teaching and learning process as opposed to a culminating activity.</p>
<p>Since Brown’s research in 2004, other researchers have also recognized that there are different purposes for assessment. Earl <span class="citation">(<a href="#ref-earlAssessmentLearningUsing2013" role="doc-biblioref">2013</a>)</span> comments that these purposes might sometimes conflict with each other, such as when assessment might be used for both formative feedback and also as evidence supporting a summative grade. Earl contends that the purposes of assessment can be categorized as assessment <em>of</em> learning (summative judgements of learner knowledge), assessment <em>for</em> learning (formative feedback loops guiding and directing future learning), and assessment <em>as</em> learning (learners using metacognitive skills to self-regulate in learning contexts). While Earl’s taxonomy is primarily focused on how instructors and learners use assessment data, others note that conceptions of assessment extend well beyond this. DeLuca et al.<span class="citation">(<a href="#ref-delucaEstablishingFoundationValid2013" role="doc-biblioref">2013</a>)</span>, for example, proposed that there are four predominant conceptions of assessment among teachers, namely, “(a) assessment as testing, (b) assessment as format, (c) assessment as purpose and (d) assessment as process” (p. 110). They argue that their taxonomy represents an ordered progression of complexity beginning with a primary focus on summative testing and progressing through to a conception of assessment that recognizes the complexity of integrated teaching and learning processes.</p>
<div id="professional-standards-assessment-literacy" class="section level3 hasAnchor" number="0.0.1">
<h3><span class="header-section-number">0.0.1</span> Professional Standards / Assessment Literacy<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#professional-standards-assessment-literacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Title/Article</th>
<th>Citation</th>
<th>Domains</th>
<th>Standards</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Standards for Teacher Competence in Educational Assessment of Students</td>
<td><span class="citation">(<a href="#ref-aftStandardsTeacherCompetence1990" role="doc-biblioref">AFT et al., 1990</a>)</span></td>
<td>NA</td>
<td>7</td>
</tr>
<tr class="even">
<td>Principles for Fair Student Assessment Practices for Education in Canada</td>
<td><span class="citation">(<a href="#ref-jointadvisorycommitteePrinciplesFairStudent1993" role="doc-biblioref">Committee, 1993</a>)</span></td>
<td>- Developing and choosing methods for assessment <br> - Collecting assessment information <br> - Judging and scoring student performance <br> - Summarizing and interpreting results <br> - Reporting assessment findings</td>
<td>36</td>
</tr>
<tr class="odd">
<td>Assessment Literacy For the 21st Century</td>
<td><span class="citation">(<a href="#ref-stigginsAssessmentLiteracy21st1995" role="doc-biblioref">Stiggins, 1995</a>)</span></td>
<td>NA</td>
<td>5</td>
</tr>
<tr class="even">
<td>Educational Assessment Knowledge and Skills for Teachers</td>
<td><span class="citation">(<a href="#ref-brookhartEducationalAssessmentKnowledge2011" role="doc-biblioref">Brookhart, 2011</a>)</span></td>
<td>NA</td>
<td>11</td>
</tr>
<tr class="odd">
<td>Classroom Assessment Standards for PreK-12 Teachers</td>
<td><span class="citation">(<a href="#ref-klingerClassroomAssessmentStandards2015" role="doc-biblioref">Klinger et al., 2015</a>)</span></td>
<td>- Foundation <br> - Use <br> - Quality</td>
<td>17</td>
</tr>
<tr class="even">
<td>Approaches to Classroom Assessment</td>
<td><span class="citation">(<a href="#ref-delucaApproachesClassroomAssessment2016" role="doc-biblioref">DeLuca et al., 2016</a>)</span></td>
<td>- Assessment purposes <br> - Assessment process <br> - Assessment fairness <br> - Assessment theory</td>
<td>12</td>
</tr>
</tbody>
</table>
<p><span class="citation">(<a href="#ref-brookhartEducationalAssessmentKnowledge2011" role="doc-biblioref">Brookhart, 2011</a>)</span>
### Approaches to Assessment</p>
<p>DeLuca et al. <span class="citation">(<a href="#ref-delucaTeachersApproachesClassroom2016" role="doc-biblioref">2016</a>)</span> utilized this framework</p>
</div>
</div>
<div id="factors" class="section level2 unnumbered hasAnchor">
<h2>Factors<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#factors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In exploring higher education instructors’ approaches to assessment, it is helpful to look to research in the K12 sector as the idea of approaches to assessment originated in the context of K12 teaching. There have long been concerns that K12 teachers do not graduate with sufficient knowledge of assessment, even though they complete undergraduate degrees which have come to include specific courses in assessment <span class="citation">(<a href="#ref-stigginsAssessmentLiteracy1991" role="doc-biblioref">Stiggins, 1991</a>)</span>. Given this, in addition to the fact that higher education instructors generally do not encounter any specific pedagogical or assessment preparation in their graduate degrees, we can infer that the assessment capabilities of higher education instructors are much lower than those of K12 teachers. This is supported in research conducted by Massey et al. <span class="citation">(<a href="#ref-masseyAssessmentLiteracyCollege2020" role="doc-biblioref">2020</a>)</span> who investigated the impact of a semester-long instructional development course on the conceptions of assessment and assessment confidence of new faculty. Pre-course responses indicated a predominant view that assessment is primarily about summative testing to confirm that learners have retained information from didactic learning experiences. They found that the instructional development course encouraged faculty to deepen their understandings of assessment, and as they did so, their conceptions of assessment became more nuanced and complex. At the same time, following the increased depth in conceptions, researchers noted that participants’ confidence in assessment also increased.</p>
<p>Popham <span class="citation">(<a href="#ref-pophamAssessmentLiteracyTeachers2009" role="doc-biblioref">2009</a>)</span> describes two often competing types of assessments, <em>classroom</em> assessments and <em>accountability</em> assessments. Classroom assessments are typically teacher-created, although some teachers use publisher-created materials such as test banks, and are used to assign grades to learners or to inform future instruction. Accountability assessments are those which are usually government-imposed, standardized tests, most often deployed in K12 settings, although there are notable higher education contexts where such accountability tests are prominent, namely programs which prepare learners for external regulatory exams (e.g. nursing, accounting). Popham argues that the relative emphasis on either of these types of assessment will impact the decisions teachers make in their instructional and assessment approaches.</p>
<p>Offerdahl and Tomanek <span class="citation">(<a href="#ref-offerdahlChangesInstructorsAssessment2011" role="doc-biblioref">2011</a>)</span> investigated instructors’ assessment thinking in relation to being presented with new assessment strategies. They found that changes in assessment <em>practice</em> didn’t necessarily follow from changes in assessment <em>thinking</em> and that there are many factors which influence both assessment thinking and practice.</p>
<p>Willis et al. <span class="citation">(<a href="#ref-willisConceptualisingTeachersAssessment2013" role="doc-biblioref">2013</a>)</span> highlight the importance of understanding assessment literacies (plural) as being understood in relation to learning theory and that assessment is an “ethical practice that is social, dynamic, and layered” (p. 242). They situate their discussion in the idea of “horizontal” and “vertical” discourses as articulated by Bernstein <span class="citation">(<a href="#ref-bernsteinVerticalHorizontalDiscourse1999" role="doc-biblioref">1999</a>)</span>. A horizontal discourse is characterized as being common sense knowledge that is presumed to be known by local communities. It is context dependent and can be contradictory across communities while remaining internally coherent within communities. Bernstein contrasts this with the idea of vertical discourses, which are characteristically organized in a hierarchy with explicit principles which are systematically enacted (such as in the sciences) or rely on “a series of specialised languages with specialised modes of interrogation and specialised criteria for the production and circulation of texts” <span class="citation">(<a href="#ref-bernsteinVerticalHorizontalDiscourse1999" role="doc-biblioref">Bernstein, 1999, p. 159</a>)</span>, as in the social sciences. As vertical discourses rely on specialized language and expertise, they must be “decoded or translated (pedagogised)” <span class="citation">(<a href="#ref-singhPedagogisingKnowledgeBernstein2002" role="doc-biblioref">Singh, 2002, p. 4</a>)</span> in order for those outside the domain to access that particular knowledge. Willis et al. <span class="citation">(<a href="#ref-willisConceptualisingTeachersAssessment2013" role="doc-biblioref">2013</a>)</span> argue that, since teachers are influenced by both horizontal and vertical discourses, they must constantly work to balance vertical and horizontal discourses. They use the example of the vertical discourse reflected in the “measurement conception of assessment” <span class="citation">(<a href="#ref-willisConceptualisingTeachersAssessment2013" role="doc-biblioref">2013, p. 244</a>)</span> in which assessment is viewed in light of positivist scientific paradigms, behaviourist learning theory, and an emphasis on testing learning at a time removed from instruction. This discourse is seen prominently in Confucian traditions <span class="citation">(<a href="#ref-carlessTestingProductiveStudent2011" role="doc-biblioref">Carless, 2011</a>)</span>, as well as cultures that use high-stakes testing for learner advancement and teacher accountability, such as the USA <span class="citation">(<a href="#ref-pophamAssessmentLiteracyTeachers2009" role="doc-biblioref">Popham, 2009</a>)</span>. Contrary to this prominent vertical discourse is the horizontal discourse grounded in socio-cultural perspectives exemplified in local cultures which downplay the role of high-stakes testing and instead focus on assessment as an integral component of learning <span class="citation">(<a href="#ref-delucaAssessmentLiteracyDevelopment2010" role="doc-biblioref">DeLuca &amp; Klinger, 2010</a>)</span>.</p>
<p>Looney et al. <span class="citation">(<a href="#ref-looneyReconceptualisingRoleTeachers2017" role="doc-biblioref">2017</a>)</span> argue that teacher assessment literacy is too instrumental a focus and that <em>conceptions of assessment</em> tend to neglect affective feelings related to teacher self-efficacy. They argue that teacher assessment identity encompasses these factors and that there are significant ontological dimensions to assessment. Teachers assess the way they do because of <em>who</em> they are in addition to what they know and are able to do.</p>
<p><span class="citation">(<a href="#ref-delucaPoliciesProgramsPractices2019" role="doc-biblioref">DeLuca, Willis, et al., 2019</a>)</span></p>
<div id="assessment-cultures" class="section level3 unnumbered hasAnchor">
<h3>Assessment Cultures<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#assessment-cultures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="citation">(<a href="#ref-masseyAssessmentLiteracyCollege2020" role="doc-biblioref">Massey et al., 2020</a>)</span></p>
<p><span class="citation">(<a href="#ref-birenbaumConceptualizingAssessmentCulture2014" role="doc-biblioref">Birenbaum, 2014</a>)</span> - assessment for learning cycle corresponds to inquiry sycle</p>
<p><span class="citation">(<a href="#ref-delucaExploringAssessmentCultures2021" role="doc-biblioref">DeLuca et al., 2021</a>)</span>
<span class="citation">(<a href="#ref-birenbaumAssessmentCultureTesting2016" role="doc-biblioref">Birenbaum, 2016</a>)</span></p>
<p>[delucaCrossculturalComparisonGerman2020]
[willisConceptualisingTeachersAssessment2013]
<span class="citation">(<a href="#ref-hebertOnlineRemoteProctoring2021" role="doc-biblioref">Hébert, 2021</a>)</span></p>
</div>
<div id="impact-of-technology-on-approaches-to-assessment-in-higher-education" class="section level3 hasAnchor" number="0.0.2">
<h3><span class="header-section-number">0.0.2</span> Impact Of Technology On Approaches To Assessment In Higher Education<a href="a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education.html#impact-of-technology-on-approaches-to-assessment-in-higher-education" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While digital technologies have become ubiquitous in higher education <span class="citation">(<a href="#ref-broadfootAssessmentTwentyFirstCenturyLearning2016" role="doc-biblioref">Broadfoot, 2016</a>)</span>, research suggests that the impact of technology on pedagogy, including assessment practices, in higher education has not kept up with the potential. Garrison et al. <span class="citation">(<a href="#ref-garrisonThinkingCollaborativelyEducational2015" role="doc-biblioref">2015</a>)</span> introduce the idea of <em>shared metacognition</em> as being a necessary competency for learners in 21st century higher education. They build a case that modern learners must contend with <em>supercomplexity</em> <span class="citation">(<a href="#ref-barnettWillLearnBeing2007" role="doc-biblioref">Barnett, 2007</a>)</span>, which refers to the open-endedness and ambiguity characteristic of modern society and culture. Supercomplexity is both compounded and mitigated through the integration of digital technologies in higher education. While there is additional cognitive load associated with learning to learn through technology, it is also true that technology can help learners organize information through <em>cognitive offloading</em> <span class="citation">(<a href="#ref-riskoCognitiveOffloading2016" role="doc-biblioref">Risko &amp; Gilbert, 2016</a>)</span>. Supercomplexity requires learners to engage in both cognitive offloading and shared metacognition in order to be successful, especially in light of the goals of modern universities.</p>
<p>Garrison et al. employ the same argument as Shepard <span class="citation">(<a href="#ref-shepardRoleAssessmentLearning2000" role="doc-biblioref">2000</a>)</span> when they assert that modern technology-mediated learning environments tend to be grounded in out-dated approaches.</p>
<p>Some researchers use terms, such as “technology-<em>enhanced</em>”, “technology-<em>enabled</em>, or”technology-<em>rich</em>” <span class="citation">(<a href="#ref-eyalDigitalAssessmentLiteracy2012" role="doc-biblioref">Eyal, 2012, p. 37</a>)</span> assessment, which show a positivity bias towards the use of technoloogy in higher education. Although this terminology will be a component of the search process, this review will use the more neutral term “technology-mediated assessment” whenever possible in light of the fact that assessment is not always “enhanced”, “enabled”, or “enriched” with the use of technology.</p>
<p>Modern universities are under pressure from public and private funding agencies <span class="citation">(<a href="#ref-hebertOnlineRemoteProctoring2021" role="doc-biblioref">Hébert, 2021</a>)</span> and employers to demonstrate that graduates are equipped for the demands of citizenship in the 21st century <span class="citation">(<a href="#ref-pellegrinoPerspectivesIntegrationTechnology2010" role="doc-biblioref">Pellegrino &amp; Quellmalz, 2010</a>)</span>. Technological changes in society have impacted how people live, work, play, and learn in many ways leading to additional pressures on universities to respond to new realities <span class="citation">(<a href="#ref-worldeconomicforumFutureJobsReport2020" role="doc-biblioref">Forum, 2020</a>)</span>. As a result, universities have incorporated many technologies into how they operate, including student information systems, faculty career tracking systems, and learning management systems, to name a few. Technologies have also impacted how instructors teach, with many instructors incorporating digital tools such as the aforementioned learning management systems, but also in-class slide-decks to accompany lectures (often replacing older technologies, such as overhead projectors and chalk boards), digital response systems, digital distribution and gathering of documents, digital feedback, networked learning environments (i.e., blogs, git-based repositories, wikis, and other collaborative digital learning environments), and, more recently, artificially intelligent agents and algorithms used to interact with learners and even evaluate learner artifacts. Many of these technologies have allowed both universities and instructors to automate, and therefore scale up, processes and procedures that formerly consumed significant time and labour, however, in most cases, they have not fundamentally changed the kind of work that is being done <span class="citation">(<a href="#ref-broadfootAssessmentTwentyFirstCenturyLearning2016" role="doc-biblioref">Broadfoot, 2016</a>)</span>. For example, automated grading of selected-response tests using a learning management system or a bubble sheet has greatly reduced the amount of time it takes to score selected-response tests, saving instructors significant time. However, this technology has not fundamentally changed the selected-response test itself. Similarly, collecting digital artifacts, like essays, has improved tracking and likely reduced the number of lost essays, but it has not fundamentally changed the nature of the assessment task. Despite the widespread adoption of technologies for many tasks in higher education, it would seem that technology has not yet significantly transformed how instructors encourage or assess learning in their classes <span class="citation">(<a href="#ref-garrisonThinkingCollaborativelyEducational2015" role="doc-biblioref">Garrison &amp; Akyol, 2015</a>)</span>.</p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-aftStandardsTeacherCompetence1990" class="csl-entry">
AFT, NCME, &amp; NEA. (1990). <em>Standards for <span>Teacher Competence</span> in <span>Educational Assessment</span> of <span>Students</span></em>.
</div>
<div id="ref-barnettWillLearnBeing2007" class="csl-entry">
Barnett, R. (2007). <em>A <span>Will</span> to <span>Learn</span>: <span>Being</span> a <span>Student</span> in an <span>Age</span> of <span>Uncertainty</span></em>. <span>McGraw-Hill Education</span>.
</div>
<div id="ref-bernsteinVerticalHorizontalDiscourse1999" class="csl-entry">
Bernstein, B. (1999). Vertical and <span>Horizontal Discourse</span>: <span>An Essay</span>. <em>British Journal of Sociology of Education</em>, <em>20</em>(2), 157–173. <a href="https://doi.org/ftmsvc">https://doi.org/ftmsvc</a>
</div>
<div id="ref-birenbaumConceptualizingAssessmentCulture2014" class="csl-entry">
Birenbaum, M. (2014). Conceptualizing <span>Assessment Culture</span> in <span>School</span>. In C. Wyatt-Smith, V. Klenowski, &amp; P. Colbert (Eds.), <em>Designing <span>Assessment</span> for <span>Quality Learning</span></em> (Vol. 1, pp. 285–302). <span>Springer Netherlands</span>. <a href="https://doi.org/10.1007/978-94-007-5902-2_18">https://doi.org/10.1007/978-94-007-5902-2_18</a>
</div>
<div id="ref-birenbaumAssessmentCultureTesting2016" class="csl-entry">
Birenbaum, M. (2016). Assessment <span>Culture Versus Testing Culture</span>: <span>The Impact</span> on <span>Assessment</span> for <span>Learning</span>. In D. Laveault &amp; L. Allal (Eds.), <em>Assessment for <span>Learning</span>: <span>Meeting</span> the <span>Challenge</span> of <span>Implementation</span></em> (Vol. 4, pp. 275–292). <span>Springer International Publishing</span>. <a href="https://doi.org/10.1007/978-3-319-39211-0_16">https://doi.org/10.1007/978-3-319-39211-0_16</a>
</div>
<div id="ref-blackAssessmentClassroomLearning1998" class="csl-entry">
Black, P., &amp; Wiliam, D. (1998). Assessment and <span>Classroom Learning</span>. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>5</em>(1), 7–74. <a href="https://doi.org/fpnss4">https://doi.org/fpnss4</a>
</div>
<div id="ref-bloomLearningMasteryInstruction1968" class="csl-entry">
Bloom, B. (1968). Learning for <span>Mastery</span>. <span>Instruction</span> and <span>Curriculum</span>. <span>Regional Education Laboratory</span> for the <span>Carolinas</span> and <span>Virginia</span>, <span>Topical Papers</span> and <span>Reprints</span>, <span>Number</span> 1. <em>Evaluation Comment</em>, <em>1</em>(2), 12.
</div>
<div id="ref-broadfootAssessmentTwentyFirstCenturyLearning2016" class="csl-entry">
Broadfoot, P. (2016). Assessment for <span>Twenty-First-Century Learning</span>: <span>The Challenges Ahead</span>. In M. J. Spector, B. B. Lockee, &amp; M. D. Childress (Eds.), <em>Learning, <span>Design</span>, and <span>Technology</span></em> (pp. 1–23). <span>Springer International Publishing</span>. <a href="https://doi.org/10.1007/978-3-319-17727-4_64-1">https://doi.org/10.1007/978-3-319-17727-4_64-1</a>
</div>
<div id="ref-brookhartEducationalAssessmentKnowledge2011" class="csl-entry">
Brookhart, S. M. (2011). Educational <span>Assessment Knowledge</span> and <span>Skills</span> for <span>Teachers</span>. <em>Educational Measurement: Issues and Practice</em>, <em>30</em>, 3–12. <a href="https://doi.org/cwcqj4">https://doi.org/cwcqj4</a>
</div>
<div id="ref-brownTeachersConceptionsAssessment2004" class="csl-entry">
Brown, G. T. L. (2004). Teachers’ conceptions of assessment: Implications for policy and professional development. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>11</em>(3), 301–318. <a href="https://doi.org/10.1080/0969594042000304609">https://doi.org/10.1080/0969594042000304609</a>
</div>
<div id="ref-carlessTestingProductiveStudent2011" class="csl-entry">
Carless, D. (2011). <em>From testing to productive student learning: Implementing formative assessment in confucian-heritage settings</em>. <span>Routledge</span>.
</div>
<div id="ref-jointadvisorycommitteePrinciplesFairStudent1993" class="csl-entry">
Committee, J. A. (1993). <em>Principles for <span>Fair Student Assessment Practices</span> for <span>Education</span> in <span>Canada</span></em>. <span>University Of Alberta</span>.
</div>
<div id="ref-crooksImpactClassroomEvaluation1988" class="csl-entry">
Crooks, T. J. (1988). The <span>Impact</span> of <span>Classroom Evaluation Practices</span> on <span>Students</span>. <em>Review of Educational Research</em>, <em>58</em>(4), 438–481. <a href="https://doi.org/dvd8nf">https://doi.org/dvd8nf</a>
</div>
<div id="ref-delucaEstablishingFoundationValid2013" class="csl-entry">
DeLuca, C., Chavez, T., &amp; Cao, C. (2013). Establishing a foundation for valid teacher judgement on student learning: The role of pre-service assessment education. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>20</em>(1), 107–126. <a href="https://doi.org/gj5v98">https://doi.org/gj5v98</a>
</div>
<div id="ref-delucaDifferentialSituatedView2019" class="csl-entry">
DeLuca, C., Coombs, A., Macgregor, S., &amp; Rasooli, A. (2019). Toward a differential and situated view of assessment literacy: <span>Studying</span> teachers’ responses to classroom assessment scenarios. <em>Frontiers in Education</em>, <em>4</em>. <a href="https://doi.org/gh5k63">https://doi.org/gh5k63</a>
</div>
<div id="ref-delucaAssessmentLiteracyDevelopment2010" class="csl-entry">
DeLuca, C., &amp; Klinger, D. (2010). Assessment literacy development: Identifying gaps in teacher candidates’ learning. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>17</em>, 419–438. <a href="https://doi.org/c2cw5r">https://doi.org/c2cw5r</a>
</div>
<div id="ref-delucaApproachesClassroomAssessment2016" class="csl-entry">
DeLuca, C., LaPointe-McEwan, D., &amp; Luhanga, U. (2016). Approaches to classroom assessment inventory: <span>A</span> new instrument to support teacher assessment literacy. <em>Educational Assessment</em>, <em>21</em>, 248–266. <a href="https://doi.org/gfgtsg">https://doi.org/gfgtsg</a>
</div>
<div id="ref-delucaExploringAssessmentCultures2021" class="csl-entry">
DeLuca, C., Rickey, N., &amp; Coombs, A. (2021). Exploring assessment across cultures: <span>Teachers</span>’ approaches to assessment in the <span>U</span>.<span>S</span>., <span>China</span>, and <span>Canada</span>. <em>Cogent Education</em>, <em>8</em>(1), 1921903. <a href="https://doi.org/gjxvc7">https://doi.org/gjxvc7</a>
</div>
<div id="ref-delucaTeachersApproachesClassroom2016" class="csl-entry">
DeLuca, C., Valiquette, A., Coombs, A., LaPointe-McEwan, D., &amp; Luhanga, U. (2016). Teachers’ approaches to classroom assessment: A large-scale survey. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>25</em>, 355–375. <a href="https://doi.org/gh5k6p">https://doi.org/gh5k6p</a>
</div>
<div id="ref-delucaPoliciesProgramsPractices2019" class="csl-entry">
DeLuca, C., Willis, J., Cowie, B., Harrison, C., Coombs, A., Gibson, A., &amp; Trask, S. (2019). Policies, <span>Programs</span>, and <span>Practices</span>: <span>Exploring</span> the <span>Complex Dynamics</span> of <span>Assessment Education</span> in <span>Teacher Education Across Four Countries</span>. <em>Frontiers in Education</em>, <em>4</em>, 132. <a href="https://doi.org/gh5k2r">https://doi.org/gh5k2r</a>
</div>
<div id="ref-earlAssessmentLearningUsing2013" class="csl-entry">
Earl, L. M. (2013). <em>Assessment as learning: Using classroom assessment to maximize student learning</em> (Second edition). <span>Corwin Press</span>.
</div>
<div id="ref-eyalDigitalAssessmentLiteracy2012" class="csl-entry">
Eyal, L. (2012). Digital <span>Assessment Literacy</span> the <span>Core Role</span> of the <span>Teacher</span> in a <span>Digital Environment</span>. <em>Journal of Educational Technology &amp; Society</em>, <em>15</em>(2), 37–49.
</div>
<div id="ref-fletcherFacultyStudentsConceptions2012" class="csl-entry">
Fletcher, R. B., Meyer, L. H., Anderson, H., Johnston, P., &amp; Rees, M. (2012). Faculty and <span>Students Conceptions</span> of <span>Assessment</span> in <span>Higher Education</span>. <em>Higher Education</em>, <em>64</em>(1), 119–133. <a href="https://doi.org/ctccpq">https://doi.org/ctccpq</a>
</div>
<div id="ref-worldeconomicforumFutureJobsReport2020" class="csl-entry">
Forum, W. E. (2020). <em>The <span>Future</span> of <span>Jobs Report</span> 2020</em>. <span>World Economic Forum</span>.
</div>
<div id="ref-garrisonThinkingCollaborativelyEducational2015" class="csl-entry">
Garrison, D. R., &amp; Akyol, Z. (2015). Thinking <span>Collaboratively</span> in <span>Educational Environments</span>: <span>Shared Metacognition</span> and <span>Co-Regulation</span> in <span>Communities</span> of <span>Inquiry</span>. In J. Lock, P. Redmond, &amp; P. A. Danaher (Eds.), <em>Educational <span>Developments</span>, <span>Practices</span> and <span>Effectiveness</span></em> (pp. 39–52). <span>Palgrave Macmillan UK</span>. <a href="https://doi.org/10.1057/9781137469939_3">https://doi.org/10.1057/9781137469939_3</a>
</div>
<div id="ref-harlenSystematicReviewImpact2002" class="csl-entry">
Harlen, W., &amp; Deakin Crick, R. (2002). A systematic review of the impact of summative assessment and tests on students’ motivation for learning. <em>Research Evidence in Education Library</em>, <em>1</em>, 151.
</div>
<div id="ref-hebertOnlineRemoteProctoring2021" class="csl-entry">
Hébert, C. (2021). Online <span>Remote Proctoring Software</span> in the <span>Neoliberal Institution</span>: <span>Measurement</span>, <span>Accountability</span>, and <span>Testing Culture</span>. <em>In Education</em>, <em>27</em>(1), 23–40. <a href="https://doi.org/10.37119/ojs2021.v27i1.507">https://doi.org/10.37119/ojs2021.v27i1.507</a>
</div>
<div id="ref-jamesAssessmentLearning2008" class="csl-entry">
James, M. (2008). Assessment and learning. In S. Swaffield (Ed.), <em>Unlocking <span>Assessment</span></em>. <span>David Fulton Publishers</span>. <a href="https://doi.org/10.4324/9780203930939">https://doi.org/10.4324/9780203930939</a>
</div>
<div id="ref-joughinAssessmentLearningJudgement2009a" class="csl-entry">
Joughin, G. (Ed.). (2009). <em>Assessment, <span>Learning</span> and <span>Judgement</span> in <span>Higher Education</span></em>. <span>Springer Netherlands</span>. <a href="https://doi.org/10.1007/978-1-4020-8905-3">https://doi.org/10.1007/978-1-4020-8905-3</a>
</div>
<div id="ref-klingerClassroomAssessmentStandards2015" class="csl-entry">
Klinger, D., McDivitt, P., Howard, B., Rogers, T., Munoz, M., &amp; Wylie, C. (2015). <em>Classroom <span>Assessment Standards</span> for <span>PreK-12 Teachers</span></em>. <span>Joint Committee on Standards for Educational Evaluation</span>.
</div>
<div id="ref-lipnevichWhatGradesMean2020" class="csl-entry">
Lipnevich, A. A., Guskey, T. R., Murano, D. M., &amp; Smith, J. K. (2020). What do grades mean? <span>Variation</span> in grading criteria in <span>American</span> college and university courses. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>27</em>(5), 480–500. <a href="https://doi.org/ghjw3k">https://doi.org/ghjw3k</a>
</div>
<div id="ref-looneyReconceptualisingRoleTeachers2017" class="csl-entry">
Looney, A., Cumming, J., van der Kleij, F. M., &amp; Harris, K. (2017). Reconceptualising the role of teachers as assessors: Teacher assessment identity. <em>Assessment in Education: Principles, Policy &amp; Practice</em>, <em>25</em>, 442–467. <a href="https://doi.org/gfkfk6">https://doi.org/gfkfk6</a>
</div>
<div id="ref-masseyAssessmentLiteracyCollege2020" class="csl-entry">
Massey, K. D., DeLuca, C., &amp; LaPointe-McEwan, D. (2020). Assessment <span>Literacy</span> in <span>College Teaching</span>: <span>Empirical Evidence</span> on the <span>Role</span> and <span>Effectiveness</span> of a <span>Faculty Training Course</span>. <em>To Improve the Academy</em>, <em>39</em>(1). <a href="https://doi.org/gj5ngz">https://doi.org/gj5ngz</a>
</div>
<div id="ref-mislevyTestTheoryReconcieved1994" class="csl-entry">
Mislevy, R. J. (1994). Test theory reconcieved. <em>ETS Research Report Series</em>, <em>1994</em>(1), i–38. <a href="https://doi.org/gjm236">https://doi.org/gjm236</a>
</div>
<div id="ref-offerdahlChangesInstructorsAssessment2011" class="csl-entry">
Offerdahl, E. G., &amp; Tomanek, D. (2011). Changes in instructors’ assessment thinking related to experimentation with new strategies. <em>Assessment and Evaluation in Higher Education</em>, <em>36</em>(7), 781–795. <a href="https://doi.org/d89z7p">https://doi.org/d89z7p</a>
</div>
<div id="ref-pellegrinoKnowingWhatStudents2001" class="csl-entry">
Pellegrino, J. W., Chudowsky, N., &amp; Glaser, R. (2001). <em>Knowing <span>What Students Know</span>: <span>The Science</span> and <span>Design</span> of <span>Educational Assessment</span></em>. <span>National Academies Press</span>. <a href="https://doi.org/10.17226/10019">https://doi.org/10.17226/10019</a>
</div>
<div id="ref-pellegrinoPerspectivesIntegrationTechnology2010" class="csl-entry">
Pellegrino, J. W., &amp; Quellmalz, E. S. (2010). Perspectives on the <span>Integration</span> of <span>Technology</span> and <span>Assessment</span>. <em>Journal of Research on Technology in Education</em>, <em>43</em>(2), 119–134. <a href="https://doi.org/ggfh8z">https://doi.org/ggfh8z</a>
</div>
<div id="ref-pophamAssessmentLiteracyTeachers2009" class="csl-entry">
Popham, W. J. (2009). Assessment <span>Literacy</span> for <span>Teachers</span>: <span>Faddish</span> or <span>Fundamental</span>? <em>Theory Into Practice</em>, <em>48</em>(1), 4–11. <a href="https://doi.org/djcn3z">https://doi.org/djcn3z</a>
</div>
<div id="ref-riskoCognitiveOffloading2016" class="csl-entry">
Risko, E. F., &amp; Gilbert, S. J. (2016). Cognitive <span>Offloading</span>. <em>Trends in Cognitive Sciences</em>, <em>20</em>(9), 676–688. <a href="https://doi.org/10.1016/j.tics.2016.07.002">https://doi.org/10.1016/j.tics.2016.07.002</a>
</div>
<div id="ref-scrivenMethodologyEvaluation1967" class="csl-entry">
Scriven, M. (1967). <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/null">The methodology of evaluation</a>. In B. O. Smith (Ed.), <em>Perspectives of curriculum evaluation</em>. <span>Rand McNally</span>.
</div>
<div id="ref-shepardRoleAssessmentLearning2000" class="csl-entry">
Shepard, L. A. (2000). The <span>Role</span> of <span>Assessment</span> in a <span>Learning Culture</span>. <em>Educational Researcher</em>, <em>29</em>(7), 4–14. <a href="https://doi.org/cw9jwc">https://doi.org/cw9jwc</a>
</div>
<div id="ref-singhPedagogisingKnowledgeBernstein2002" class="csl-entry">
Singh, P. (2002). Pedagogising <span>Knowledge</span>: <span>Bernstein</span>’s theory of the pedagogic device. <em>British Journal of Sociology of Education</em>, <em>23</em>(4), 571–582. <a href="https://doi.org/10.1080/0142569022000038422">https://doi.org/10.1080/0142569022000038422</a>
</div>
<div id="ref-skinnerBehaviourOrganisms1938" class="csl-entry">
Skinner, B. (1938). <em>The behaviour of organisms</em>. <span>Appleton-Century-Crofts</span>.
</div>
<div id="ref-stigginsAssessmentLiteracy1991" class="csl-entry">
Stiggins, R. J. (1991). Assessment <span>Literacy</span>. <em>The Phi Delta Kappan</em>, <em>72</em>(7), 534–539.
</div>
<div id="ref-stigginsAssessmentLiteracy21st1995" class="csl-entry">
Stiggins, R. J. (1995). Assessment <span>Literacy</span> for the 21st <span>Century</span>. <em>The Phi Delta Kappan</em>, <em>77</em>(3), 238–245.
</div>
<div id="ref-thorndikeElementsPsychology1905" class="csl-entry">
Thorndike, E. L. (1905). <em>The <span>Elements</span> of psychology</em>. <span>A.G. Seiler</span>.
</div>
<div id="ref-timmisRethinkingAssessmentDigital2016" class="csl-entry">
Timmis, S., Broadfoot, P., Sutherland, R., &amp; Oldfield, A. (2016). Rethinking assessment in a digital age: Opportunities, challenges and risks. <em>British Educational Research Journal</em>, <em>42</em>(3), 454–476. <a href="https://doi.org/gftz95">https://doi.org/gftz95</a>
</div>
<div id="ref-vygotskyMindSociety1978" class="csl-entry">
Vygotsky, L. S. (1978). <em>Mind in society</em> (M. Cole, V. John-Steiner, S. Scribner, &amp; E. Souberman, Eds.; A. R. Luria, Trans.). <span>Harvard University Press</span>.
</div>
<div id="ref-webbAssessmentTwentyFirstCentury2018" class="csl-entry">
Webb, M., &amp; Ifenthaler, D. (2018). Assessment as, for, and of <span>Twenty-First Century Learning Using Information Technology</span>: <span>An Overview</span>. In J. Voogt, G. Knezek, R. Christensen, &amp; K.-W. Lai (Eds.), <em>Second <span>Handbook</span> of <span>Information Technology</span> in <span>Primary</span> and <span>Secondary Education</span></em> (pp. 581–600). <span>Springer International Publishing</span>. <a href="https://doi.org/10.1007/978-3-319-71054-9_37">https://doi.org/10.1007/978-3-319-71054-9_37</a>
</div>
<div id="ref-willisConceptualisingTeachersAssessment2013" class="csl-entry">
Willis, J., Adie, L., &amp; Klenowski, V. (2013). Conceptualising teachers’ assessment literacies in an era of curriculum and assessment reform. <em>The Australian Educational Researcher</em>, <em>40</em>(2), 241–256. <a href="https://doi.org/gh5k7d">https://doi.org/gh5k7d</a>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="references.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cmadland/assessment/edit/master/02-paper-1.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Assessment in HE.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

</body>

</html>
