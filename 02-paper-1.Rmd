# A Review of the Literature on Assessment in Technology-mediated Higher Education {-}


- [A Review of the Literature on Assessment in Technology-mediated Higher Education {-}](#a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education--)
  - [Introduction](#introduction)
  - [A Brief History of Assessment Research](#a-brief-history-of-assessment-research)


## Introduction

The assessment of learning is a critical component of the work of higher education instructors, yet not enough is known about how instructors plan for and make decisions about how they will assess their students' learning. In her important article, Shepard [-@shepardRoleAssessmentLearning2000] argues that traditional assessment structures originated in past models of curriculum and instruction which were popular in the early 1900s. These curricular models emphasized the work of psychologists like Thorndike [@thorndikeElementsPsychology1905] and Skinner [@skinnerBehaviourOrganisms1938] who viewed the process of learning as being grounded in the mechanistic view of behaviourism where learning is the result of the precise and controlled input of 'knowledge' and reinforced with rewards for correct responses. As such, instructors (appropriately) designed their assessments to align with the curricular goals of the time and assessed learning by determining whether or not a learner could provide the single correct response to a given question at a time removed from the instruction.  However, in the latter half of the 20th century, when western psychologists discovered the ideas of Lev Vygotsky[@vygotskyMindSociety1978], a contemporary of the previously mentioned psychologists, curricula began to take a more social-constructivist approach that emphasized higher-order thinking, problem-solving in social contexts, and metacognitive skills over rote memorization. Unfortunately, it seemed that the efficiencies of testing memory, recognition, and recall through selected-response tests were too deeply embedded in the practices of HE instructors who resisted changing their assessments to match the new curricular goals. 

Shepard argues for the need to integrate assessment and instruction in such a way as to engage learners in authentic performance tasks more suited to modern understandings of cognition. It appears now that, in the twenty years since Shepard wrote her paper, the goals of early 21st century curricula have continued to diverge from those of the 20th century with the World Economic Forum identifying competencies in collaboration, analytical thinking, creative problem-solving, and the continual learning as being priorities for 21st century employers [@worldeconomicforumFutureJobsReport2020]. Consequently, models of assessment which prioritize testing skills in a manner aligned with 20th century curricular models are no longer adequate because they no longer align with the priorities of modern HE [@broadfootAssessmentTwentyFirstCenturyLearning2016; @crooksImpactClassroomEvaluation1988; @pellegrinoPerspectivesIntegrationTechnology2010; @timmisRethinkingAssessmentDigital2016]. 

Despite Shepard's exhortation to integrate modern curricular goals with 
aligned assessment practices, both local and systemic change in this area has been elusive [@broadfootAssessmentTwentyFirstCenturyLearning2016; @earlAssessmentLearningUsing2013]. This is in part because the approaches that individual instructors take to assessment are driven by complex factors at the individual level as well as local and systemic levels [@blackAssessmentClassroomLearning1998; @delucaDifferentialSituatedView2019; @willisConceptualisingTeachersAssessment2013]. The variety of factors, combined with the relative freedom instructors have to design their courses and assessments leads to approaches to assessment that are variable, idiosyncratic, and often influenced by their own past experiences rather than a deep understanding of assessment theory [@lipnevichWhatGradesMean2020; @masseyAssessmentLiteracyCollege2020].

One prominent and under-researched factor that has become ubiquitous in society and higher education is the influence of digital technologies on instructors approaches to assessment [@pellegrinoPerspectivesIntegrationTechnology2010; @webbAssessmentTwentyFirstCentury2018; @broadfootAssessmentTwentyFirstCenturyLearning2016], a factor driven, in part, by the COVID-19 pandemic and the sudden shift to emergency remote teaching for the vast majority of higher education institutions. 

Researchers are engaged in important work exploring how K12 teachers approach assessment in their classrooms, including DeLuca et al.'s [-@delucaApproachesClassroomAssessment2016] *Approaches to Classroom Assessment Inventory*, but there has been less work in relation to higher education. DeLuca et al. [-@delucaExploringAssessmentCultures2021] showed that assessment at the K12 level in Canada, China, and the USA is a complex process driven by both systemic and local factors. 

Given the reported gap between the goals of modern curricula and assessment practices, the complexity of factors that shape instructors' approaches to assessment, the influx of technology in higher education, and the smaller research base exploring approaches to assessment among higher education instructors, the purpose of this literature review will be to synthesize and analyze the literature related to approaches to assessment among higher education instructors. The review will begin with a survey of historical conceptions of assessment, followed by a deeper analysis of the literature since 2010 with a focus on assessment in technologically-mediated higher education. 

This review is guided by four research questions:

1. What factors shape higher education instructors' approaches to assessment?
2. What are the major themes or patterns in the literature related to approaches to assessment in higher education?  
3. What are the major themes or patterns in the literature related to the impact of technology on assessment in higher education?  
4. What gaps exist in the literature related to approaches to assessment in technology-mediated higher education?


## A Brief History of Assessment Research








<!--

### Impact of Technology on Approaches to Assessment in higher Education

Some researchers use terms, such as "technology-*enhanced*", "technology-*enabled*, or "technology-*rich*" assessment, which show a positivity bias towards the use of technoloogy in higher education. Although this terminology will be a component of the search process, this review will use the more neutral term "technology-mediated assessment" whenever possible in light of the fact that assessment is not always "enhanced", "enabled", or "enriched" with the use of technology.

Modern universities are under pressure from public and private funding agencies and employers to demonstrate that graduates are equipped for the demands of citizenship in the 21st century [@pellegrinoPerspectivesIntegrationTechnology2010]. Technological changes in society have impacted how people live, work, play, and learn in many ways leading to additional pressures on universities to respond to new realities [@worldeconomicforumFutureJobsReport2020]. As a result, universities have incorporated many technologies into how they operate, including student information systems, faculty career tracking systems, and learning management systems, to name a few. Technologies have also impacted how instructors teach, with many instructors incorporating digital tools such as the aforementioned learning management systems, but also in-class slide-decks to accompany lectures (often replacing older technologies, such as overhead projectors and chalk boards), digital response systems, digital distribution and gathering of documents, digital feedback, networked learning environments (i.e., blogs, git-based repositories, wikis, and other collaborative digital learning environments), and, more recently, artificially intelligent agents and algorithms used to interact with learners and even evaluate learner artifacts. Many of these technologies have allowed both universities and instructors to automate, and therefore scale up, processes and procedures that formerly consumed significant time and labour, however, in most cases, they have not fundamentally changed the kind of work that is being done [@broadfootAssessmentTwentyFirstCenturyLearning2016]. For example, automated grading of selected-response tests using a learning management system or a bubble sheet has greatly reduced the amount of time it takes to score selected-response tests, saving instructors significant time. However, this technology has not fundamentally changed the selected-response test itself. Similarly, collecting digital artifacts, like essays, has improved tracking and likely reduced the number of lost essays, but it has not fundamentally changed the nature of the assessment task. Despite the widespread adoption of technologies for many tasks in higher education would seem that technology has not yet significantly transformed how instructors assess learning in their classes.
-->

