# A Review of the Literature on Assessment in Technology-mediated Higher Education {-}

<!--
- [A Review of the Literature on Assessment in Technology-mediated Higher Education {-}](#a-review-of-the-literature-on-assessment-in-technology-mediated-higher-education--)
  - [Introduction](#introduction)
-->

## Introduction

The assessment of learning is a critical component of the work of higher education instructors. In Canada, there is important research at the K12 level exploring how teachers approach assessment in their classrooms, including DeLuca et al.'s [-@delucaApproachesClassroomAssessment2016] *Approaches to Classroom Assessment Inventory*, but there has been less work in relation to higher education. Research does show that instructors in higher education are less prepared in the areas of pedagogy and assessment than their K12 colleagues, suggesting that the approaches to assessment taken by higher education instructors are likely to be more variable, idiosyncratic, and influenced by instructors' own past experiences rather than a deep understanding of assessment theory [@lipnevichWhatGradesMean2020; @masseyAssessmentLiteracyCollege2020]. DeLuca et al. [-@delucaExploringAssessmentCultures2021] showed that assessment at the K12 level in Canada, China, and the USA is a complex process driven by both systemic and local factors. Adding to the complexity of assessment is the profusion of technology in higher education [@pellegrinoPerspectivesIntegrationTechnology2010; @webbAssessmentTwentyFirstCentury2018; @broadfootAssessmentTwentyFirstCenturyLearning2016], a factor driven, in part, by the COVID-19 pandemic and the sudden shift to emergency remote teaching for the vast majority of higher education institutions. Given the complexity of assessment, combined with the relatively low academic preparation in the areas of pedagogy and assessment for higher education instructors, the influx of technology in higher education, and the smaller research base exploring approaches to assessment among higher education instructors, the purpose of this literature review will be to synthesize and analyze the literature related to approaches to assessment among higher education instructors. The review will begin with a survey of historical conceptions of assessment, followed by a deeper analysis of the literature since 2010 with a focus on assessment in technologically-mediated higher education. 

This review is guided by three research questions:

1. What are the major themes or patterns in the literature related to approaches to assessment in higher education?  
2. What are the major themes or patterns in the literature related to the impact of technology on assessment in higher education?  
3. What gaps exist in the literature related to approaches to assessment in technology-mediated higher education?


Some researchers use terms, such as "technology-*enhanced*", "technology-*enabled*, or "technology-*rich*" assessment, which show a positivity bias towards the use of technoloogy in higher education. Although this terminology will be a component of the search process, this review will use the more neutral term "technology-mediated assessment" whenever possible in light of the fact that assessment is not always "enhanced", "enabled", or "enriched" with the use of technology.





<!--
Modern universities are under pressure from public and private funding agencies and employers to demonstrate that graduates are equipped for the demands of citizenship in the 21st century [@pellegrinoPerspectivesIntegrationTechnology2010]. Technological changes in society have impacted how people live, work, play, and learn in many ways leading to additional pressures on universities to respond to new realities [@worldeconomicforumFutureJobsReport2020]. As a result, universities have incorporated many technologies into how they operate, including student information systems, faculty career tracking systems, and learning management systems, to name a few. Technologies have also impacted how instructors teach, with many instructors incorporating digital tools such as the aforementioned learning management systems, but also in-class slide-decks to accompany lectures (often replacing older technologies, such as overhead projectors and chalk boards), digital response systems, digital distribution and gathering of documents, digital feedback, networked learning environments (i.e., blogs, git-based repositories, wikis, and other collaborative digital learning environments), and, more recently, artificially intelligent agents and algorithms used to interact with learners and even evaluate learner artifacts. Many of these technologies have allowed both universities and instructors to automate, and therefore scale up, processes and procedures that formerly consumed significant time and labour, however, in most cases, they have not fundamentally changed the kind of work that is being done [@broadfootAssessmentTwentyFirstCenturyLearning2016]. For example, automated grading of selected-response tests using a learning management system or a bubble sheet has greatly reduced the amount of time it takes to score selected-response tests, saving instructors significant time. However, this technology has not fundamentally changed the selected-response test itself. Similarly, collecting digital artifacts, like essays, has improved tracking and likely reduced the number of lost essays, but it has not fundamentally changed the nature of the assessment task. Despite the widespread adoption of technologies for many tasks in higher education would seem that technology has not yet significantly transformed how instructors assess learning in their classes.
-->

